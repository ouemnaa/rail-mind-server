Error Type: BadRequestError
Error Message: Error code: 400 - {'error': {'message': '`reasoning_effort` is not supported with this model', 'type': 'invalid_request_error'}}

Traceback:
Traceback (most recent call last):
  File "C:\rail-mind-server\agents\resolution_agent\resolver.py", line 463, in call_llm_judge
    completion = client.chat.completions.create(
        model=model_name,
    ...<12 lines>...
        stop=None
    )
  File "C:\Users\user\AppData\Local\Programs\Python\Python313\Lib\site-packages\groq\resources\chat\completions.py", line 461, in create
    return self._post(
           ~~~~~~~~~~^
        "/openai/v1/chat/completions",
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<45 lines>...
        stream_cls=Stream[ChatCompletionChunk],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\user\AppData\Local\Programs\Python\Python313\Lib\site-packages\groq\_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\user\AppData\Local\Programs\Python\Python313\Lib\site-packages\groq\_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.BadRequestError: Error code: 400 - {'error': {'message': '`reasoning_effort` is not supported with this model', 'type': 'invalid_request_error'}}
